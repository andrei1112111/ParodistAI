{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
      "state": {},
      "version_major": 2,
      "version_minor": 0
      }
    } 
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Da__DxS5kRk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0d0cb2-6ab9-4096-f0eb-9a788ab05c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.47.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruGPT-3.5-13B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"ai-forever/ruGPT-3.5-13B\",\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True\n",
        "    )"
      ],
      "metadata": {
        "id": "PrxiuzSvkXFl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668,
          "referenced_widgets": [
            "6c6aeaef825e4459a25bf8e46675248e",
            "8d83cbb3cf0e48a3aa5c6b0ce49c4f6d",
            "97f634eeb91547df90697f388e0b539c",
            "9ecd8965e42f4027b0629b24419d638a",
            "428067223c5a458e8c5b25ce361cd810",
            "ac361c5a0f2b466087419dbadf56dd7f",
            "58ba569029324c70b208339639fe00ba",
            "cb56873735084702975d2e2a2085c1a0",
            "a1a2cf7a80604d4b979f3fe6488e0e81",
            "aaff9d34b8b144f1b8dc7fd0906f962f",
            "9360ac9dd0bf4a7ea64f6056b3e47af4",
            "ce1173a84d0c4a25b4bab46a699d8ac6",
            "66d96f17798c44bc847c44605238e8a5",
            "f94ef2d057d34e68b5dd65495f909833",
            "c65a9b72543d4180a27145be30bb5715",
            "eae70cc681214b408a1a5ae9888980f2",
            "3b1db88a00684c2c847ec721ff0676ae",
            "597336e1c4e741318ebc211455e129b9",
            "5a0d8c1d5d4844c3969a37191705facb",
            "55efb67f0ef14a5aa4099418b2e04e33",
            "e787d15eb24f4bde89e8ee7fa181ad0e",
            "a89725f7bf2d4760bc0c075506c8530c",
            "6dc4e9259e9d4e44836236b9dad6681b",
            "aef7b832ac19482194a9b3bde20147c8",
            "5e2122cd23d04951ad9bcad75822d0a3",
            "261a5a4d2704426ea0f2b0cc84251b5e",
            "4c972388b0b746deb34dbcc12db64a3d",
            "85bab27e53054f49bdbe3831e4d88a83",
            "bc8a10ebf17a49c7ac1ce6f914ec58b3",
            "a8d00acfa99a4341bed1663ec38b9693",
            "be89d7fe42604794a1de3eeecdb83060",
            "72d023356b2f456dae41f85e5078b919",
            "364048e8c76242fdbd2162bb60f9e006",
            "7353c453c37a4f8c8450ec0fe491d0cc",
            "51f523852dd1400fae6014331f256bb0",
            "1c54f57d275c4367aa3b7e70fee346e8",
            "146cac9be6bb4c6d93a063e83c38a5ee",
            "77910479c96f43dfa3274007376476d2",
            "2822fe730ca64628ab65ad6259f026a9",
            "dc5e005c6e34482eabf7196e909916eb",
            "66ff97b82eea470ea132b75236d0acb1",
            "1ff168480ce545b7ba78325b2a77f0ce",
            "a4599860737d421c93bae4fa7c1e14e6",
            "adf08f60190348f584f4c74b2f305929",
            "586e78daed564e8aaed4b34482261187",
            "d92ae5d7360e4f46961f92dd4ab6cd0b",
            "fc93b3b5a35d4eaa982b33c17fa3e98e",
            "47e888cde3694852a2a4c900e2a045df",
            "05c37d48e34c4e85be6601a924e0ee95",
            "ddcfb0542cb047ddb5b49adc458fe46d",
            "71a164393a664d26ab241f0aaca19645",
            "0000e367792e475c84b49f43b1c9279e",
            "cee108e421784be5947c5b2ca4b4c351",
            "dce30faf2fad4a20bd1901ede27c1265",
            "c2dce844984645ce9249598c8d96e2a2",
            "7a32daca2e5a41d79c7224b7fcce1ebe",
            "f5f11673195b4d44ac4e6d22eaecc418",
            "a92f876af9be4830b82c2af097c6a506",
            "9c50562f69fe4c808693d468ccded017",
            "9c238ac96fd34b30abb92606d67c5ad0",
            "3138f69757b249b28da9b12e369f96e2",
            "8f9234b13c49444d87dd4fd8d7c51652",
            "9fbc34d62f2f4891a1b3cea54f8cbbb2",
            "8586c80becb34f2ab6db7215812699d8",
            "92f3276d4d724fb7bb82f890a49de4aa",
            "57489818554f476dbffd397468dfb771",
            "63c4fd486359484db12777b9ce515500",
            "22f53b89d8004534a4f27aac9fdbc0cc",
            "8f83e5089a664913b76e828a6d8970d2",
            "2a1b880c29eb4cfd8c801b343031f3ca",
            "b7b521fe3b4a4df6ab621b8d85d37e54",
            "902d2f452a8e468686ca82b1b723e6d3",
            "cd2c2bcf96c74710b7f2650c8822a625",
            "dc0ac3c2311c4cd7911e45b0f9e52c07",
            "41c333c00bf34aad99aad41ba3494d90",
            "9f400f9f8ba04892af5306a95f5c45d2",
            "b0c8687f773e4b2bb9bb73d28b436911",
            "f5502d47b7ff4146b5ffb96efcbed377",
            "668de345e6c1478d9b34020ae9caa986",
            "4cf61a9b9fb345ff8209cd139ba191ce",
            "edff0289b80e45a987bbd275185df10c",
            "78291b4abdd547c3905a92b265590587",
            "e891fa9b62fd47c9b1fa760e35b7fe3e",
            "cb529af12cd848b5b7e57bcd984bade2",
            "6191f0ee39084291bc6cb563cbca1e61",
            "75e542e3473243c5bdec8fb1be248cfe",
            "3a2b17d8b31b44f685cb22e4a10c0ee9",
            "8d6ccd1793f4440291a251755a711ebe",
            "3286836a36ab4497bfc7edf06293d0c4",
            "78aaa16c9dcf4476962bd28cd186bfbc",
            "b941fe8ee13347718c2267e11abc0988",
            "dc99c9952f1e480fb4d2ad60a725f9bb",
            "15a5e51b600c4e9e869193142dde516d",
            "588027b98d1c4daa9c953831aca8ec29",
            "53af0494eb98475bbb7e64e237f4bbb9",
            "fe44a5633a914d2691db52dd17cb3cfa",
            "2edb026936d44c06a8015f332080dd6b",
            "783df90476a64785bce10196d9f89156",
            "60e74c3ccb764716bffa80a075a0d862",
            "632307b43a744da59a2ae80188439ab1",
            "2ea455a018544f4b9504f6cfabcda0d3",
            "124418285ab54674857b2c5e34d10e1a",
            "163f831a68e1420e8debeb9a132f042c",
            "dba2af32308041cc9690613b719f3257",
            "ae40ca658122424b99b8044c4ae0da42",
            "8674c922ccea4352bd791d4def4b99ce",
            "fb1add831bca4369b1e29784d38e5f42",
            "2ec1563ce1bc401480e8663cf03d4cc7",
            "6ed708ffb6dc4197aa52ae1271f93847",
            "bf9da06115bc4db899b3f3b13891ca84",
            "1534f754654845dd81d1408972544b49",
            "fb72daf76fd7455b8fdd58fccf4d050a",
            "3bd2a96b79004defa3dbe22bd16205e8",
            "3c850063351e4efda33b3f98932a01ec",
            "434f9c24cf19458ba3ba6a0bdfccaebe",
            "ee59867191164160b588a79b1482fc0e",
            "038e0e5f02a14bcc98ae50f38b822c78",
            "0895642240974a2284cee17006a4863a",
            "ea21ed3ad05249f4b9e95a3ee410bd8a",
            "74d74e9d06b94380aeea605847715c80",
            "b0608412cb6b45aa92a63852b44fdc53",
            "bc0cd9c2159b4bbd99d29bd028422bd1",
            "cbd816a3870a48aba89650f90c187415",
            "88e398a08e904d5ab5feba5b3c535c51",
            "4dbbabad506b4048bdec873c1a1d4f69",
            "e0fd5e88fe0b4ac18212f1c2d8af4a05",
            "b4a9986c770748efa010b98d19fb81f3",
            "add13b66066c4eed9f017e86cb06b6d6",
            "8397b82a2d45414f8b5afded0549eab6",
            "2471b0c6122a4bd2a065d73dd011c8e9",
            "3fffcc99b2734e858bc82a70be60fb19",
            "d5525642aeb6429ea043eb45b4341b76",
            "6a55444faa804685929a586038732b86",
            "e665e1e0b81d44689bb9386bd3773352",
            "2840f6229796446d80a63139a5e270e1",
            "a10b5115e19c4212a95c1cf8b92d6602",
            "73b658479b38475f84646a5cdb7e1c29",
            "e4aa5f1546744f38aed33810083b65ee",
            "2a10a2429cea462786c9ee219edb797e",
            "083c985818a44d2ab304ef7535cc177e",
            "b6f364f72b254a71b2a3a34733f3aa0e",
            "52ac536ac7fb4d3294fc7dc93e7ac148",
            "6fa596b886ea4aa48b06db40413ae8f6",
            "7e4df55dafa7479d8d886a675fff81a3",
            "5d651779f9104f729fbbfce97bf5b798",
            "1e1fceda98094c098a6b3c2890685f93",
            "7455404c0b87463e8b9cd0c16856ad30",
            "771150320ddb41b4a29ea011bb736101",
            "5d268cf701ae49edbe7611bbb4e5e718",
            "a8a6323de0634a9e96475c8a728d7773",
            "33f542079319485b9ec5455e79ddd1d0",
            "24ec5c410f584be1a510770244b5e1fd",
            "f8dc62fb5318402eaf7edf5d878c98b6",
            "9870b2bde9354076b0e643305349fae5",
            "611d4314b22540669f86bde259ad6847",
            "7f791db549f14d87a5098d52745ecb66",
            "0eb1f5a9f26349699e26e5d62bf23630",
            "0d3901f487f34601864dea9e465898cc",
            "a9f72803cccf4cafb0c4ac4966fbcae6",
            "d953fb08fccf4b36982103ae532502bc",
            "57e80dbabe08421b92a060f650c04aed",
            "ef05b17e00d54fd4bab0dba6e4ce6c86",
            "041415f24993406f97b0bfc87e1bae48",
            "4ef1e0787160416693d0d0fbb92f136c",
            "5faa0e96351a42e291f2cdf29507856b",
            "ea3932b4a72f4a4fbcb012e632ab224b",
            "e34306842e894b1aafbdb2bdb4437ad1",
            "161b2d26fa854ed0af29b4ed35b2fad2",
            "117cf31606434d55bafa1ecaed438054",
            "a9bbc6daa63c46438be2bb69b68c13f8",
            "3c21150e99344c13b888d4462c36d428",
            "4d47e557a35f435081060b49425fcd2f",
            "9c7890c0e5804455b0a7a6674c7f2818",
            "242934b27ebf47b29a8ad564bff9bd0f",
            "30e050f0b4bc482f951fc3025bb9cea2",
            "fd310a4d3c3d48068a8efda1f2cd4882"
          ]
        },
        "outputId": "9fcd29ff-98b6-41a9-ed09-8e8cb4a9809d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/933 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c6aeaef825e4459a25bf8e46675248e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce1173a84d0c4a25b4bab46a699d8ac6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dc4e9259e9d4e44836236b9dad6681b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/582 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7353c453c37a4f8c8450ec0fe491d0cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/782 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "586e78daed564e8aaed4b34482261187"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a32daca2e5a41d79c7224b7fcce1ebe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63c4fd486359484db12777b9ce515500"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00006-of-00006.bin:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5502d47b7ff4146b5ffb96efcbed377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00004-of-00006.bin:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3286836a36ab4497bfc7edf06293d0c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00006.bin:   0%|          | 0.00/9.68G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "632307b43a744da59a2ae80188439ab1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00003-of-00006.bin:   0%|          | 0.00/9.68G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1534f754654845dd81d1408972544b49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00005-of-00006.bin:   0%|          | 0.00/9.79G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc0cd9c2159b4bbd99d29bd028422bd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00006.bin:   0%|          | 0.00/9.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a55444faa804685929a586038732b86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e4df55dafa7479d8d886a675fff81a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "611d4314b22540669f86bde259ad6847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea3932b4a72f4a4fbcb012e632ab224b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to('cuda:0')\n"
      ],
      "metadata": {
        "id": "OMsaI1AZkliy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(request):\n",
        "  encoded_input = tokenizer(\n",
        "      request,\n",
        "      return_tensors='pt',\n",
        "      add_special_tokens=False\n",
        "  ).to('cuda:0')\n",
        "\n",
        "  output = model.generate(\n",
        "    **encoded_input,\n",
        "    num_beams=2,\n",
        "    do_sample=True,\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.8,\n",
        "    repetition_penalty=1.2,\n",
        "    no_repeat_ngram_size=3,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        "  )\n",
        "\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "yGtainydkeZQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = predict(\"Стих в стиле Пушкина был бы таким:\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HdRJ2WCn-3D",
        "outputId": "92cc5c70-c6ec-4910-8a11-34023d89b1b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Стих в стиле Пушкина был бы таким:\n",
            "\n",
            "«Вышла на берег Катюша,\n",
            "\n",
            "Бросила в воду венок.\n",
            "\n",
            "Выплыл венок и поплыл по реке,\n",
            "А за венком поплыла и Катюша».\n",
            "\n",
            "На этом стихотворение заканчивалось бы, но можно было бы приписать: «А за Катюшей поплыл и Иван-царевич». \n",
            "\n",
            "Стихотворение в стиле Некрасова было бы таково: \n",
            "\n",
            "«Выплыла на бережок\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = predict(\"Короткий стих из 4 строк в стиле Маяковского был бы таким: \\n\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1lVocsQuk5l",
        "outputId": "3e1d8865-8cfd-4cbf-d233-e58e63af3e89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Короткий стих из 4 строк в стиле Маяковского был бы таким: \n",
            "\n",
            "\"А за окном \n",
            "\n",
            "Вьюга, \n",
            "\n",
            "вьюга. \n",
            "\n",
            "А за окошком \n",
            "\n",
            "Ночь. \n",
            " \n",
            "А в окошке \n",
            "\n",
            "Звезды. \n",
            " \n",
            "\n",
            "И в душе моей \n",
            "\n",
            "Тоже \n",
            "\n",
            "Звездная ночь\". \n",
            "\n",
            "Я бы так написал, если бы умел писать стихи. Но, к сожалению, я не умею писать стихи, и поэтому я написал то, что написал. И мне очень жаль, что я не могу написать лучше. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = predict(\"\"\"Сейчас я напишу короткую басню в стиле И.А. Крылова.\n",
        "Использю животных, придумаю ситуацию и мораль.\n",
        "Не копирую существующие тексты и не вставляю ссылки. Вот она: \"\"\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIReAu0Zun_q",
        "outputId": "5d3eb50d-0a3d-4af0-f0af-4a0e6b5d0f6b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сейчас я напишу короткую басню в стиле И.А. Крылова.\n",
            "Использю животных, придумаю ситуацию и мораль.\n",
            "Не копирую существующие тексты и не вставляю ссылки. Вот она: \n",
            "\n",
            "Жил-был на свете таракан.\n",
            "Он жил себе, не тужил.\n",
            "И вот однажды он влюбился.\n",
            "Влюбился в самочку.\n",
            "\n",
            "Таракан был молодой,\n",
            "И самочка была молодая.\n",
            "Они встречались каждый день.\n",
            "Но вот однажды\n",
            "\n",
            "Настал момент, когда они должны были расстаться.\n",
            "Самочка должна была улететь в теплые края.\n",
            "А таракан остался зимовать.\n",
            "Наступила зима.\n",
            "Холодно\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I64y3D2DkS4k"
      }
    }
  ]
}